{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1505cb2a",
   "metadata": {},
   "source": [
    "### Data Collection - Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc87aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import os, glob\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.yelp.com/developers/documentation/v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdb026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Yelp API credentials\n",
    "import yelp_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = yelp_credentials.client_id\n",
    "api_key = yelp_credentials.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query API for restaurant details - test\n",
    "\n",
    "url = 'https://api.yelp.com/v3/businesses/search'\n",
    "headers = {'Authorization': 'Bearer {}'.format(api_key)}\n",
    "\n",
    "params = {'term': 'restaurant', \n",
    "          'location': 'London SW19',\n",
    "          'limit': 50}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch response data\n",
    "response = requests.get(url=url, headers=headers, params=params, timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91903e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check response headers\n",
    "print(response.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdbe3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return response as JSON object\n",
    "data_dict = response.json()\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a83c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "\n",
    "restaurants = {'id':[],\n",
    "               'alias':[],\n",
    "               'name':[],\n",
    "               'review_count':[],\n",
    "               'cat_1':[],\n",
    "               'cat_2':[],\n",
    "               'cat_3':[],\n",
    "               'cat_4':[],\n",
    "               'cat_5':[],\n",
    "               'rating':[],\n",
    "               'longitude':[],\n",
    "               'latitude':[],\n",
    "               'transaction_1':[],\n",
    "               'transaction_2':[],\n",
    "               'transaction_3':[],\n",
    "               'price':[],\n",
    "               'address1':[],\n",
    "               'address2':[],\n",
    "               'address3':[],\n",
    "               'city': [],\n",
    "               'zip_code':[],\n",
    "               'country':[]}\n",
    "\n",
    "for item in data_dict['businesses']:\n",
    "    try:\n",
    "        restaurants['id'].append(item['id'])\n",
    "    except:\n",
    "        restaurants['id'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['alias'].append(item['alias'])\n",
    "    except:\n",
    "        restaurants['alias'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['name'].append(item['name'])\n",
    "    except:\n",
    "        restaurants['name'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['review_count'].append(item['review_count'])\n",
    "    except:\n",
    "        restaurants['review_count'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['cat_1'].append(item['categories'][0]['title'])\n",
    "    except:\n",
    "        restaurants['cat_1'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['cat_2'].append(item['categories'][1]['title'])\n",
    "    except:\n",
    "        restaurants['cat_2'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['cat_3'].append(item['categories'][2]['title'])\n",
    "    except:\n",
    "        restaurants['cat_3'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['cat_4'].append(item['categories'][3]['title'])\n",
    "    except:\n",
    "        restaurants['cat_4'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['cat_5'].append(item['categories'][4]['title'])\n",
    "    except:\n",
    "        restaurants['cat_5'].append(np.nan) \n",
    "    try:\n",
    "        restaurants['rating'].append(item['rating'])\n",
    "    except:\n",
    "        restaurants['rating'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['longitude'].append(item['coordinates']['longitude'])\n",
    "    except:\n",
    "        restaurants['longitude'].append(np.nan)    \n",
    "    try:\n",
    "        restaurants['latitude'].append(item['coordinates']['latitude'])\n",
    "    except:\n",
    "        restaurants['latitude'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['transaction_1'].append(item['transactions'][0])\n",
    "    except:\n",
    "        restaurants['transaction_1'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['transaction_2'].append(item['transactions'][1])\n",
    "    except:\n",
    "        restaurants['transaction_2'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['transaction_3'].append(item['transactions'][2])\n",
    "    except:\n",
    "        restaurants['transaction_3'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['price'].append(item['price'])\n",
    "    except:\n",
    "        restaurants['price'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['address1'].append(item['location']['address1'])\n",
    "    except:\n",
    "        restaurants['address1'].append(np.nan)\n",
    "    try:\n",
    "        restaurants['address2'].append(item['location']['address2'])\n",
    "    except:\n",
    "        restaurants['address2'].append(np.nan)          \n",
    "    try:\n",
    "        restaurants['address3'].append(item['location']['address3'])\n",
    "    except:\n",
    "        restaurants['address3'].append(np.nan)     \n",
    "    try:\n",
    "        restaurants['city'].append(item['location']['city'])\n",
    "    except:\n",
    "        restaurants['city'].append(np.nan)     \n",
    "    try:\n",
    "        restaurants['zip_code'].append(item['location']['zip_code'])\n",
    "    except:\n",
    "        restaurants['zip_code'].append(np.nan) \n",
    "    try:\n",
    "        restaurants['country'].append(item['location']['country'])\n",
    "    except:\n",
    "        restaurants['country'].append(np.nan)  \n",
    "                \n",
    "restaurants = pd.DataFrame(restaurants)\n",
    "restaurants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99d611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1786c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to extract restaurant details from JSON and convert to dataframe\n",
    "\n",
    "def convert_to_df(data_dict):\n",
    "\n",
    "    restaurants = {'id':[],\n",
    "                   'alias':[],\n",
    "                   'name':[],\n",
    "                   'review_count':[],\n",
    "                   'cat_1':[],\n",
    "                   'cat_2':[],\n",
    "                   'cat_3':[],\n",
    "                   'cat_4':[],\n",
    "                   'cat_5':[],\n",
    "                   'rating':[],\n",
    "                   'longitude':[],\n",
    "                   'latitude':[],\n",
    "                   'transaction_1':[],\n",
    "                   'transaction_2':[],\n",
    "                   'transaction_3':[],\n",
    "                   'price':[],\n",
    "                   'address1':[],\n",
    "                   'address2':[],\n",
    "                   'address3':[],\n",
    "                   'city': [],\n",
    "                   'zip_code':[],\n",
    "                   'country':[]}\n",
    "\n",
    "    for item in data_dict['businesses']:\n",
    "        try:\n",
    "            restaurants['id'].append(item['id'])\n",
    "        except:\n",
    "            restaurants['id'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['alias'].append(item['alias'])\n",
    "        except:\n",
    "            restaurants['alias'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['name'].append(item['name'])\n",
    "        except:\n",
    "            restaurants['name'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['review_count'].append(item['review_count'])\n",
    "        except:\n",
    "            restaurants['review_count'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['cat_1'].append(item['categories'][0]['title'])\n",
    "        except:\n",
    "            restaurants['cat_1'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['cat_2'].append(item['categories'][1]['title'])\n",
    "        except:\n",
    "            restaurants['cat_2'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['cat_3'].append(item['categories'][2]['title'])\n",
    "        except:\n",
    "            restaurants['cat_3'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['cat_4'].append(item['categories'][3]['title'])\n",
    "        except:\n",
    "            restaurants['cat_4'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['cat_5'].append(item['categories'][4]['title'])\n",
    "        except:\n",
    "            restaurants['cat_5'].append(np.nan) \n",
    "        try:\n",
    "            restaurants['rating'].append(item['rating'])\n",
    "        except:\n",
    "            restaurants['rating'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['longitude'].append(item['coordinates']['longitude'])\n",
    "        except:\n",
    "            restaurants['longitude'].append(np.nan)    \n",
    "        try:\n",
    "            restaurants['latitude'].append(item['coordinates']['latitude'])\n",
    "        except:\n",
    "            restaurants['latitude'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['transaction_1'].append(item['transactions'][0])\n",
    "        except:\n",
    "            restaurants['transaction_1'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['transaction_2'].append(item['transactions'][1])\n",
    "        except:\n",
    "            restaurants['transaction_2'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['transaction_3'].append(item['transactions'][2])\n",
    "        except:\n",
    "            restaurants['transaction_3'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['price'].append(item['price'])\n",
    "        except:\n",
    "            restaurants['price'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['address1'].append(item['location']['address1'])\n",
    "        except:\n",
    "            restaurants['address1'].append(np.nan)\n",
    "        try:\n",
    "            restaurants['address2'].append(item['location']['address2'])\n",
    "        except:\n",
    "            restaurants['address2'].append(np.nan)          \n",
    "        try:\n",
    "            restaurants['address3'].append(item['location']['address3'])\n",
    "        except:\n",
    "            restaurants['address3'].append(np.nan)     \n",
    "        try:\n",
    "            restaurants['city'].append(item['location']['city'])\n",
    "        except:\n",
    "            restaurants['city'].append(np.nan)     \n",
    "        try:\n",
    "            restaurants['zip_code'].append(item['location']['zip_code'])\n",
    "        except:\n",
    "            restaurants['zip_code'].append(np.nan) \n",
    "        try:\n",
    "            restaurants['country'].append(item['location']['country'])\n",
    "        except:\n",
    "            restaurants['country'].append(np.nan)  \n",
    "        \n",
    "    restaurants = pd.DataFrame(restaurants)\n",
    "    return restaurants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a382e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# London postcodes\n",
    "\n",
    "postcodes_lon = ['WC1', 'WC2', 'EC1', 'EC2', 'EC3', 'EC4',\n",
    "                 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10',\n",
    "                 'E11', 'E12', 'E13', 'E14', 'E15', 'E16', 'E17', 'E18', 'E20',\n",
    "                 'N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 'N9', 'N10',\n",
    "                 'N11', 'N12', 'N13', 'N14', 'N15', 'N16', 'N17', 'N18', 'N19', 'N20',\n",
    "                 'N21', 'N22', 'NW1', 'NW2', 'NW3', 'NW4', 'NW5', 'NW6', 'NW7', \n",
    "                 'NW8', 'NW9', 'NW10', 'NW11', \n",
    "                 'SE1', 'SE2', 'SE3', 'SE4', 'SE5', 'SE6', 'SE7', 'SE8', 'SE9', \n",
    "                 'SE10', 'SE11', 'SE12', 'SE13', 'SE14', 'SE15', 'SE16', 'SE17', \n",
    "                 'SE18', 'SE19', 'SE20', 'SE21', 'SE22', 'SE23', 'SE24', 'SE25',\n",
    "                 'SE26', 'SE27', 'SE28',\n",
    "                 'SW1', 'SW2', 'SW3', 'SW4', 'SW5', 'SW6', 'SW7', 'SW8', 'SW9',\n",
    "                 'SW10', 'SW11', 'SW12', 'SW13', 'SW14', 'SW15', 'SW16', \n",
    "                 'SW17', 'SW18', 'SW19', 'SW20', \n",
    "                 'W1', 'W2', 'W3', 'W4', 'W5', 'W6', 'W7', 'W8', 'W9', 'W10',\n",
    "                 'W11', 'W12', 'W13', 'W14',\n",
    "                 'BR1', 'BR2', 'BR3', 'BR4', 'BR5', 'BR6', 'BR7',\n",
    "                 'CR0', 'CR2', 'CR3', 'CR4', 'CR5', 'CR7', 'CR8', 'CR9', \n",
    "                 'DA1', 'DA5', 'DA6', 'DA7', 'DA8',\n",
    "                 'EN1', 'EN2', 'EN3', 'EN4', 'EN5', 'EN8', 'EN9',\n",
    "                 'HA0', 'HA1', 'HA2', 'HA3', 'HA4', 'HA5', 'HA6', 'HA7', 'HA8', 'HA9',\n",
    "                 'IG1', 'IG2', 'IG3', 'IG4', 'IG5', 'IG6', 'IG7', 'IG8', 'IG9',\n",
    "                 'KT1', 'KT2', 'KT3', 'KT4', 'KT5', 'KT6', 'KT8', 'KT9',\n",
    "                 'RM1', 'RM2', 'RM3', 'RM4', 'RM5', 'RM6', 'RM7', 'RM8', 'RM9',\n",
    "                 'SM1', 'SM2', 'SM3', 'SM4', 'SM5', 'SM6', 'SM7', \n",
    "                 'TW1', 'TW2', 'TW3', 'TW4', 'TW5', 'TW6', 'TW7', 'TW8', 'TW9',\n",
    "                 'UB1', 'UB2', 'UB3', 'UB4', 'UB5', 'UB6', 'UB7', 'UB8', 'UB9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134234af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manchester postcodes\n",
    "\n",
    "postcodes_man = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', \n",
    "                 'M11', 'M12', 'M13', 'M14', 'M15', 'M16', 'M17', 'M18', 'M19', 'M20',\n",
    "                 'M21', 'M22', 'M23', 'M24', 'M25', 'M26', 'M27', 'M28', 'M29', 'M30', \n",
    "                 'M31', 'M32', 'M33', 'M34', 'M35', 'M38', 'M40',\n",
    "                 'M41', 'M43', 'M44', 'M45', 'M46', 'M50', 'M60', 'M61', 'M90', 'M99']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9baa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liverpool postcodes\n",
    "\n",
    "postcodes_liv = ['L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9', 'L10', \n",
    "                 'L11', 'L12', 'L13', 'L14', 'L15', 'L16', 'L17', 'L18', 'L19', 'L20', \n",
    "                 'L21', 'L22', 'L23', 'L24', 'L25', 'L26', 'L27', 'L28', 'L29', 'L30', \n",
    "                 'L31', 'L32', 'L33', 'L34', 'L35', 'L36', 'L37', 'L38', 'L39', 'L40']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861773c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define postcodes for search parameters\n",
    "postcodes = postcodes_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00251ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query API (multiple postcodes and result pages) and save to csv\n",
    "\n",
    "url = 'https://api.yelp.com/v3/businesses/search'\n",
    "headers = {'Authorization': 'Bearer {}'.format(api_key)}\n",
    "\n",
    "for postcode in postcodes:\n",
    "    for offset in range(0, 600, 50):\n",
    "        params = {'term': 'restaurant', \n",
    "                  'location': 'London {}'.format(postcode),\n",
    "                  'locale': 'en_GB',\n",
    "                  'offset': offset,\n",
    "                  'limit': 50}\n",
    "        response = requests.get(url=url, headers=headers, params=params, timeout=10)\n",
    "        data_dict = response.json()\n",
    "        df = convert_to_df(data_dict)\n",
    "        df.to_csv('rest_lond_{}_{}.csv'.format(postcode, offset), index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4db434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define different search terms\n",
    "search_terms = ['restaurant', 'pub', 'takeaway', 'fast food', 'cafe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c84ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define postcodes for search parameters\n",
    "postcodes = postcodes_liv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feacbd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query API (multiple search terms, postcodes and result pages) and save to csv\n",
    "\n",
    "url = 'https://api.yelp.com/v3/businesses/search'\n",
    "headers = {'Authorization': 'Bearer {}'.format(api_key)}\n",
    "\n",
    "for term in search_terms:\n",
    "    for postcode in postcodes:\n",
    "        for offset in range(0, 800, 50):\n",
    "            params = {'term': term, \n",
    "                      'location': 'Liverpool {}'.format(postcode),\n",
    "                      'radius': 10000,\n",
    "                      'locale': 'en_GB',\n",
    "                      'offset': offset,\n",
    "                      'limit': 50}\n",
    "            response = requests.get(url=url, headers=headers, params=params, timeout=10)\n",
    "            data_dict = response.json()\n",
    "            df = convert_to_df(data_dict)\n",
    "            df.to_csv('rest_liv_{}_{}_{}.csv'.format(term, postcode, offset), index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ed666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c60712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50321011",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/katjakrempel/Desktop/capstone/rest_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(os.path.join(path, 'rest_*.csv'))\n",
    "df_from_file = (pd.read_csv(f) for f in all_files)\n",
    "df_merged = pd.concat(df_from_file)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed051de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'Unnamed: 0' column\n",
    "df_merged.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "df_merged.drop_duplicates(inplace=True)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa075710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv \n",
    "df_merged.to_csv('rest_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285b8de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/katjakrempel/Desktop/capstone/rest_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ffc735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e475b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de26714a",
   "metadata": {},
   "source": [
    "### Join Yelp and FSA data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd02373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load FSA data\n",
    "fsa = pd.read_csv('/Users/katjakrempel/Desktop/capstone/all_fsa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee8ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Yelp data\n",
    "yelp = pd.read_csv('/Users/katjakrempel/Desktop/capstone/rest_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be601648",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values in longitude and latitude\n",
    "# fsa = fsa.dropna(subset=['longitude', 'latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values in longitude and latitude\n",
    "# yelp = yelp.dropna(subset=['longitude', 'latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e59ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85864c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values in BusinessName and PostCode\n",
    "fsa = fsa.dropna(subset=['BusinessName', 'PostCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b56d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values in name and zip_code\n",
    "yelp = yelp.dropna(subset=['name', 'zip_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd2a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to remove prefix and special characters from restaurant name\n",
    "def clean_name(name):\n",
    "    if name.lower().startswith(\"the \"):\n",
    "        name = name[4:]\n",
    "    return name.replace(\"&\", \"and\").replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "# name = \"The Fox & Anchor\"\n",
    "# name = \"Nando's\"\n",
    "# clean_name(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a82a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean restaurant names in FSA data set\n",
    "fsa['BusinessName'] = fsa['BusinessName'].apply(clean_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean restaurant names in Yelp data set\n",
    "yelp['name'] = yelp['name'].apply(clean_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf8f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique identifier column in FSA data set\n",
    "# fsa['geocode'] = fsa['longitude'].astype(str) + \", \" + fsa['latitude'].astype(str)\n",
    "fsa['name_postc'] = fsa['BusinessName'].str.lower() + \", \" + fsa['PostCode'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique identifier column in Yelp data set\n",
    "# yelp['geocode'] = yelp['longitude'].astype(str) + \", \" + yelp['latitude'].astype(str)\n",
    "yelp['name_postc'] = yelp['name'].str.lower() + \", \" + yelp['zip_code'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60817f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join dataframes on geocode\n",
    "# subset_geocode = pd.merge(fsa, yelp, on='geocode', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_geocode.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92165b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_geocode[['BusinessName', 'AddressLine1', 'longitude_x', 'latitude_x', 'name', 'address1', 'longitude_y', 'latitude_y']][subset_geocode['city']=='London']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a89333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join dataframes on name and postcode\n",
    "subset_name_postc = pd.merge(fsa, yelp, on=['name_postc'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b11de",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name_postc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aae2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv \n",
    "subset_name_postc.to_csv('fsa_yelp_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd62ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/katjakrempel/Desktop/capstone/fsa_yelp_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7f771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080b15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ede5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4e4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c113f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
